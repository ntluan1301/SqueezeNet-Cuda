{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:41.093394Z",
     "iopub.status.busy": "2025-08-21T03:47:41.093122Z",
     "iopub.status.idle": "2025-08-21T03:47:51.406584Z",
     "shell.execute_reply": "2025-08-21T03:47:51.405918Z",
     "shell.execute_reply.started": "2025-08-21T03:47:41.093375Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "from numba import cuda, float32\n",
    "import time\n",
    "import torch.nn as nn\n",
    "print('torch', torch.__version__)\n",
    "print('numpy', np.__version__)\n",
    "print('matplotlib', plt.matplotlib.__version__)\n",
    "\n",
    "# Thiết lập phát sinh ngẫu nhiên có thể tái lập\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.408258Z",
     "iopub.status.busy": "2025-08-21T03:47:51.407752Z",
     "iopub.status.idle": "2025-08-21T03:47:51.413534Z",
     "shell.execute_reply": "2025-08-21T03:47:51.412875Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.408231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def run_softmax_cuda(x_np):\n",
    "    B, C, H, W = x_np.shape\n",
    "    @cuda.jit(cache=True)\n",
    "    def softmax_Cuda(inp, out):\n",
    "        # tọa độ output\n",
    "        b_idx = cuda.blockIdx.x  # mỗi block xử lý 1 sample trong batch\n",
    "        idx   = cuda.threadIdx.x   # mỗi thread xử lý 1 trong 10 phần tử\n",
    "        temp = cuda.shared.array(10, dtype=np.float32)\n",
    "        temp[idx] = inp[b_idx, idx, 0, 0]\n",
    "        cuda.syncthreads()\n",
    "        sum_exp = 0.0\n",
    "        for i in range(10):\n",
    "            sum_exp +=  math.exp(temp[i])\n",
    "        cuda.syncthreads() \n",
    "        out[b_idx, idx] = math.exp(temp[idx]) / sum_exp\n",
    "    d_out = cuda.device_array((B, C), dtype=np.float32)\n",
    "    bpg_x = 10\n",
    "    bpg_z = B\n",
    "    softmax_Cuda[B, 10](\n",
    "        x_np, d_out\n",
    "    )\n",
    "    cuda.synchronize()\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.414468Z",
     "iopub.status.busy": "2025-08-21T03:47:51.414253Z",
     "iopub.status.idle": "2025-08-21T03:47:51.429170Z",
     "shell.execute_reply": "2025-08-21T03:47:51.428572Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.414451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_softmax_backward(output,Y):\n",
    "    B,C = output.shape\n",
    "    @cuda.jit(cache=True) \n",
    "    def softmax_backward(inp,y,out):\n",
    "        b = cuda.blockIdx.x\n",
    "        c = cuda.threadIdx.x\n",
    "        out[b,c,0,0]=(inp[b,c]-y[b,c])*1/B\n",
    "    d_out = cuda.device_array((B,C,1,1),dtype=np.float32)\n",
    "    softmax_backward[B,C](output,Y,d_out)\n",
    "    cuda.synchronize()\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.431574Z",
     "iopub.status.busy": "2025-08-21T03:47:51.430826Z",
     "iopub.status.idle": "2025-08-21T03:47:51.444844Z",
     "shell.execute_reply": "2025-08-21T03:47:51.444270Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.431550Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_global_average_Cuda(x,TPB=32):\n",
    "    B, C, H, W = x.shape\n",
    "    @cuda.jit(cache=True)\n",
    "    def Global_average_Cuda(inp, out):\n",
    "        x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        if x < B*C:\n",
    "            b = x // C\n",
    "            c = x % C\n",
    "            acc = 0\n",
    "            for i in range(H):\n",
    "                for j in range(W):\n",
    "                    acc+=inp[b,c,i,j]\n",
    "            out[b,c,0,0] = acc/(H*W)\n",
    "    griddim = (B * C + TPB - 1)//TPB\n",
    "    d_out = cuda.device_array((B, C, 1, 1), dtype=np.float32)\n",
    "    Global_average_Cuda[griddim, TPB](\n",
    "        x, d_out\n",
    "    )\n",
    "    cuda.synchronize()\n",
    "\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.445758Z",
     "iopub.status.busy": "2025-08-21T03:47:51.445575Z",
     "iopub.status.idle": "2025-08-21T03:47:51.463729Z",
     "shell.execute_reply": "2025-08-21T03:47:51.463204Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.445743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_avgpool_backward(inp,TPB=16):\n",
    "    B,C,_,_ = inp.shape\n",
    "    H_out,W_out = 13,13\n",
    "    @cuda.jit(cache=True)\n",
    "    def avgpool_backward(inp_1,out):\n",
    "        z = cuda.blockIdx.z\n",
    "        b = z // C\n",
    "        c = z % C\n",
    "        x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        y = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "        if x < H_out and y < W_out:\n",
    "           out[b,c,y,x] = inp_1[b,c,0,0]/(H_out*W_out) \n",
    "    d_out = cuda.device_array((B,C,H_out,W_out), dtype = np.float32)\n",
    "    bpx = (H_out + TPB -1)//TPB\n",
    "    bpy = (W_out + TPB -1)//TPB\n",
    "    bpz = B*C\n",
    "    grid_dim=(bpx,bpy,bpz)\n",
    "    block_dim=(TPB,TPB,1)\n",
    "    avgpool_backward[grid_dim,block_dim](inp,d_out)\n",
    "    cuda.synchronize()\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.464696Z",
     "iopub.status.busy": "2025-08-21T03:47:51.464537Z",
     "iopub.status.idle": "2025-08-21T03:47:51.474919Z",
     "shell.execute_reply": "2025-08-21T03:47:51.474538Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.464682Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_conv2d_cuda_shared_2(x_conv, w_conv, b_conv, P=2, S=2, TPB=16):\n",
    "    B, C, H, W = x_conv.shape\n",
    "    F, _, K, _ = w_conv.shape\n",
    "\n",
    "    # Tính output size\n",
    "    H_pad = H + 2*P\n",
    "    W_pad = W + 2*P\n",
    "    H_out = (H_pad - K)//S + 1\n",
    "    W_out = (W_pad - K)//S + 1\n",
    "\n",
    "    # Tính tile size cho shared memory\n",
    "    tile_h = (TPB - 1) * S + K\n",
    "    tile_w = tile_h\n",
    "    @cuda.jit(cache=True)\n",
    "    def conv2d_cuda_shared(inp, filters, bias, out):\n",
    "        # Shared memory 3D: [C, tile_h, tile_w]\n",
    "        shmem = cuda.shared.array((C, tile_h, tile_w), float32)\n",
    "    \n",
    "        # Tách batch và filter\n",
    "        z = cuda.blockIdx.z\n",
    "        b = z // F\n",
    "        f = z % F\n",
    "    \n",
    "        # Tọa độ output\n",
    "        x_out = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        y_out = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "    \n",
    "        # Góc trên–trái của tile trên inp đã pad\n",
    "        x0 = cuda.blockIdx.x * cuda.blockDim.x * S\n",
    "        y0 = cuda.blockIdx.y * cuda.blockDim.y * S\n",
    "        for c in range(C):\n",
    "            for ly in range(cuda.threadIdx.y, tile_h, cuda.blockDim.y):\n",
    "                gy = y0 + ly-P\n",
    "                for lx in range(cuda.threadIdx.x, tile_w, cuda.blockDim.x):\n",
    "                    gx = x0 + lx-P\n",
    "                    # nếu ngoài biên input thì gán 0, còn lại đọc inp\n",
    "                    if 0 <= gy < H and 0 <= gx < W:\n",
    "                        shmem[c, ly, lx] = inp[b, c, gy, gx]\n",
    "                    else:\n",
    "                        shmem[c, ly, lx] = 0.0\n",
    "        cuda.syncthreads()\n",
    "    \n",
    "        # 2) Tính convolution nếu trong vùng output\n",
    "        if b < B and f < F and y_out < H_out and x_out < W_out:\n",
    "            acc = float32(0.0)\n",
    "            for c in range(C):\n",
    "                for ky in range(K):\n",
    "                    for kx in range(K):\n",
    "                        sy = cuda.threadIdx.y * S + ky\n",
    "                        sx = cuda.threadIdx.x * S + kx\n",
    "                        acc += shmem[c, sy, sx] * filters[f, c, ky, kx]\n",
    "            acc += bias[f]\n",
    "            out[b, f, y_out, x_out] = acc\n",
    "    d_out = cuda.device_array((B, F, H_out, W_out), dtype=np.float32)\n",
    "    # grid & block dims\n",
    "    bpg_x = (W_out + TPB - 1) // TPB\n",
    "    bpg_y = (H_out + TPB - 1) // TPB\n",
    "    bpg_z = B * F\n",
    "    grid_dims  = (bpg_x, bpg_y, bpg_z)\n",
    "    block_dims = (TPB, TPB, 1)\n",
    "    # start = time.time()\n",
    "    conv2d_cuda_shared[grid_dims, block_dims](x_conv, w_conv, b_conv, d_out)\n",
    "    cuda.synchronize()\n",
    "    # time_cu_shared = time.time() - start\n",
    "\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.476021Z",
     "iopub.status.busy": "2025-08-21T03:47:51.475776Z",
     "iopub.status.idle": "2025-08-21T03:47:51.498377Z",
     "shell.execute_reply": "2025-08-21T03:47:51.497661Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.475997Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_conv2d_cuda(x, w, b, P=2, S=2, TPB=16):\n",
    "    B, C, H, W = x.shape\n",
    "    F, _, KH, KW = w.shape\n",
    "    \n",
    "    H_out = (H + 2*P - KH)//S + 1\n",
    "    W_out = (W + 2*P - KW)//S + 1\n",
    "    \n",
    "    @cuda.jit(cache=True)\n",
    "    def conv2d_cuda_kernel(input_arr, filters, bias, output):\n",
    "        z = cuda.blockIdx.z\n",
    "        b = z // F\n",
    "        f = z % F\n",
    "        \n",
    "        x_out = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        y_out = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "        \n",
    "        if x_out < W_out and y_out < H_out and b < B and f < F:\n",
    "            temp = float32(0.0)\n",
    "            # FIXED: Loop channels first, then kernel positions\n",
    "            for c in range(C):\n",
    "                for kh in range(KH):\n",
    "                    for kw in range(KW):\n",
    "                        # Calculate input coordinates\n",
    "                        y_in = y_out * S + kh - P\n",
    "                        x_in = x_out * S + kw - P\n",
    "                        \n",
    "                        # Check bounds for each kernel position\n",
    "                        if 0 <= y_in < H and 0 <= x_in < W:\n",
    "                            temp += input_arr[b, c, y_in, x_in] * filters[f, c, kh, kw]\n",
    "                        # If out of bounds, contribution is 0 (padding effect)\n",
    "            temp +=bias[f]\n",
    "            output[b, f, y_out, x_out] = temp\n",
    "    \n",
    "    d_out = cuda.device_array((B, F, H_out, W_out), dtype=np.float32)\n",
    "    bpg_x = (W_out + TPB - 1) // TPB\n",
    "    bpg_y = (H_out + TPB - 1) // TPB\n",
    "    bpg_z = B * F\n",
    "    \n",
    "    grid_dims = (bpg_x, bpg_y, bpg_z)\n",
    "    block_dims = (TPB, TPB, 1)\n",
    "    \n",
    "    conv2d_cuda_kernel[grid_dims, block_dims](x, w, b, d_out)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.499269Z",
     "iopub.status.busy": "2025-08-21T03:47:51.499081Z",
     "iopub.status.idle": "2025-08-21T03:47:51.519468Z",
     "shell.execute_reply": "2025-08-21T03:47:51.518785Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.499254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_filter_conv_backward(X, F, LO, S=1, P=1,TPB=256):\n",
    "    B, C, H, W = X.shape\n",
    "    B_f, C_f, H_f, W_f = F.shape    \n",
    "    @cuda.jit(cache=True)\n",
    "    def filter_conv_backward(inp,fil, lo, out):\n",
    "        # Mỗi thread xử lý nhiều phần tử để tận dụng tốt hơn\n",
    "        tid = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        total_elements = B_f * C_f * H_f * W_f\n",
    "        \n",
    "        if tid >= total_elements:\n",
    "            return\n",
    "            \n",
    "        # Chuyển 1D index thành 4D coordinates\n",
    "        w_idx = tid % W_f\n",
    "        tid //= W_f\n",
    "        h_idx = tid % H_f\n",
    "        tid //= H_f\n",
    "        c_idx = tid % C_f\n",
    "        b_idx = tid // C_f\n",
    "        \n",
    "        # Tính gradient cho filter[b_idx, c_idx, h_idx, w_idx]\n",
    "        temp_sum = float32(0.0)\n",
    "        for k in range(B):  # batch của input\n",
    "            for i in range(lo.shape[2]):  # height của output gradient\n",
    "                for j in range(lo.shape[3]):  # width của output gradient\n",
    "                    # Tính vị trí tương ứng trong input\n",
    "                    sy = i * S - P + h_idx\n",
    "                    sx = j * S - P + w_idx\n",
    "                    \n",
    "                    # Chỉ tính nếu vị trí hợp lệ\n",
    "                    if 0 <= sy < H and 0 <= sx < W:\n",
    "                        temp_sum += lo[k, b_idx, i, j] * inp[k, c_idx, sy, sx]\n",
    "        out[b_idx, c_idx, h_idx, w_idx] = fil[b_idx, c_idx, h_idx, w_idx] - 0.0008* temp_sum\n",
    "    \n",
    "    # Tạo output array\n",
    "    d_out = cuda.device_array((B_f, C_f, H_f, W_f), dtype=np.float32)\n",
    "    \n",
    "    # Tận dụng tối đa threads\n",
    "    total_threads_needed = B_f * C_f * H_f * W_f\n",
    "    threads_per_block = TPB  # hoặc 512 tùy GPU\n",
    "    blocks_per_grid = (total_threads_needed + TPB -1) // TPB\n",
    "    \n",
    "    # Launch kernel\n",
    "    filter_conv_backward[blocks_per_grid, threads_per_block](X,F, LO, d_out)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.520393Z",
     "iopub.status.busy": "2025-08-21T03:47:51.520184Z",
     "iopub.status.idle": "2025-08-21T03:47:51.535803Z",
     "shell.execute_reply": "2025-08-21T03:47:51.535190Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.520350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_input_conv_backward(X, F, LO, S=1, P=1, TPB=16):\n",
    "    B, C, H, W = X.shape\n",
    "    H_pad, W_pad = H + 2*P, W + 2*P\n",
    "    K = F.shape[2]  # assuming F.shape = (C_out, C_in, K, K)\n",
    "    B_f, C_f, H_f, W_f = F.shape\n",
    "    \n",
    "    @cuda.jit(cache=True)\n",
    "    def input_conv_backward(filt, lo, out):\n",
    "        x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x  # 0 -> W_pad-1\n",
    "        y = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y  # 0 -> H_pad-1\n",
    "        z = cuda.blockIdx.z\n",
    "        b = z // C\n",
    "        c = z % C\n",
    "        \n",
    "        if x < W_pad and y < H_pad:\n",
    "            temp = float32(0.0)\n",
    "            for b_f in range(B_f):  # b_f is output channel\n",
    "                for i in range(K):\n",
    "                    for j in range(K):\n",
    "                        # Calculate source coordinates in lo (output gradient)\n",
    "                        # Đây là phần quan trọng: ánh xạ từ input coordinates sang output coordinates\n",
    "                        if (y +i- (K-1))%S == 0 and (x +j- (K-1))%S == 0:\n",
    "                            sy = (y +i- (K-1))//S  # hoặc y - (K-1-i) tùy theo cách hiểu\n",
    "                            sx = (x +j- (K-1))//S  # hoặc x - (K-1-j) tùy theo cách hiểu\n",
    "                            if sy >= 0 and sy < lo.shape[2] and sx >= 0 and sx < lo.shape[3]:\n",
    "                                temp += lo[b, b_f, sy, sx] * filt[b_f, c, K-1-i, K-1-j]\n",
    "            out[b, c, y, x] = temp \n",
    "    \n",
    "    d_out = cuda.device_array((B, C, H_pad, W_pad), dtype=np.float32)\n",
    "    bpg_x = (W_pad + TPB - 1) // TPB\n",
    "    bpg_y = (H_pad + TPB - 1) // TPB\n",
    "    bpg_z = B * C\n",
    "    \n",
    "    grid_dims = (bpg_x, bpg_y, bpg_z)\n",
    "    block_dims = (TPB, TPB, 1)\n",
    "    \n",
    "    input_conv_backward[grid_dims, block_dims](F, LO, d_out)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    return d_out[:, :, P:H_pad-P, P:W_pad-P]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.538349Z",
     "iopub.status.busy": "2025-08-21T03:47:51.537951Z",
     "iopub.status.idle": "2025-08-21T03:47:51.556159Z",
     "shell.execute_reply": "2025-08-21T03:47:51.555511Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.538333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_bias_backward(inp,bias,TPB=64):\n",
    "    B,C,H,W = inp.shape\n",
    "    @cuda.jit(cache=True)\n",
    "    def bias1x1_backward(X,bi,d_out):\n",
    "        x = cuda.blockIdx.x*cuda.blockDim.x + cuda.threadIdx.x #10\n",
    "        if x < C:\n",
    "            temp = float32(0.0)\n",
    "            for b in range(B):\n",
    "                for i in range(H):\n",
    "                    for j in range(W):\n",
    "                        temp+=X[b,x,i,j] \n",
    "            d_out[x] = bi[x] - 0.0008 * temp\n",
    "    d_out = cuda.device_array((C,),dtype=np.float32)\n",
    "\n",
    "    blocksize = (C+TPB-1)//TPB\n",
    "    blockdim  = TPB   \n",
    "    bias1x1_backward[blocksize,blockdim](inp,bias,d_out)\n",
    "    cuda.synchronize()\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.557038Z",
     "iopub.status.busy": "2025-08-21T03:47:51.556840Z",
     "iopub.status.idle": "2025-08-21T03:47:51.575678Z",
     "shell.execute_reply": "2025-08-21T03:47:51.574936Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.557022Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_conv_backward(X,F,B,LO,stride=1,padding=1,TPB=16):\n",
    "    F_backward = run_filter_conv_backward(X,F,LO,stride,padding)\n",
    "    X_backward = run_input_conv_backward(X,F,LO,stride,padding,TPB)\n",
    "    bias_backward =  run_bias_backward(LO,B)\n",
    "    return X_backward,F_backward,bias_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.576690Z",
     "iopub.status.busy": "2025-08-21T03:47:51.576498Z",
     "iopub.status.idle": "2025-08-21T03:47:51.590908Z",
     "shell.execute_reply": "2025-08-21T03:47:51.590246Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.576675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_Relu_Cuda(x_relu,TPB=16):\n",
    "    B, C, H, W = x_relu.shape\n",
    "    # Chuẩn bị output trên GPU\n",
    "    d_out = cuda.device_array((B, C, H, W), dtype=np.float32)\n",
    "    bpg_x = (H + TPB - 1) // TPB\n",
    "    bpg_y = (W + TPB - 1) // TPB\n",
    "    bpg_z = B * C\n",
    "    \n",
    "    @cuda.jit(cache=True)\n",
    "    def Relu_Cuda(inp, out):\n",
    "        z = cuda.blockIdx.z\n",
    "        b = z // C\n",
    "        c = z % C\n",
    "        # tọa độ output\n",
    "        x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        y = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "        if y<H and x<W:\n",
    "            out[b, c, y, x] = inp[b, c, y, x] if inp[b, c, y, x] > 0 else 0\n",
    "    \n",
    "    grid_dims  = (bpg_x, bpg_y, bpg_z)\n",
    "    block_dims = (TPB, TPB, 1)\n",
    "    Relu_Cuda[grid_dims, block_dims](\n",
    "        x_relu, d_out\n",
    "    )\n",
    "    cuda.synchronize()\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.591709Z",
     "iopub.status.busy": "2025-08-21T03:47:51.591531Z",
     "iopub.status.idle": "2025-08-21T03:47:51.606250Z",
     "shell.execute_reply": "2025-08-21T03:47:51.605637Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.591694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_relu_backward(X,LO,TPB=16):\n",
    "    B,C,H,W = LO.shape\n",
    "    @cuda.jit(cache = True)\n",
    "    def relu_backward(inp,lo,output):\n",
    "        z = cuda.blockIdx.z\n",
    "        b = z//C\n",
    "        c = z%C\n",
    "        x = cuda.blockIdx.x*cuda.blockDim.x + cuda.threadIdx.x\n",
    "        y = cuda.blockIdx.y*cuda.blockDim.y + cuda.threadIdx.y\n",
    "        if x < H and y<W:\n",
    "            if inp[b,c,y,x]<0:\n",
    "                output[b,c,y,x]=0\n",
    "            else:\n",
    "                output[b,c,y,x] = lo[b,c,y,x]\n",
    "    d_out = cuda.device_array((B,C,H,W),dtype=np.float32)\n",
    "    bpg_x = (H + TPB - 1) // TPB\n",
    "    bpg_y = (W + TPB - 1) // TPB\n",
    "    bpg_z = B*C\n",
    "    griddim  = (bpg_x,bpg_y,bpg_z)\n",
    "    blockdim = (TPB,TPB,1)\n",
    "    relu_backward[griddim,blockdim](X,LO,d_out)\n",
    "    cuda.synchronize()\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.607087Z",
     "iopub.status.busy": "2025-08-21T03:47:51.606888Z",
     "iopub.status.idle": "2025-08-21T03:47:51.627631Z",
     "shell.execute_reply": "2025-08-21T03:47:51.626935Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.607063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_maxpool2d_cuda(x,P=0, S=2, TPB=16):\n",
    "    B, C, H, W = x.shape\n",
    "    K       = 3    \n",
    "    # Tính kích thước đầu ra\n",
    "    H_out = (H - K)//S + 1\n",
    "    W_out = (W - K)//S + 1\n",
    "    @cuda.jit(cache = True)\n",
    "    def maxpool2d_cuda(inp, out):\n",
    "        # merge batch và channel vào blockIdx.z\n",
    "        z = cuda.blockIdx.z\n",
    "        b = z // C\n",
    "        c = z % C\n",
    "    \n",
    "        # tọa độ output\n",
    "        x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        y = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "    \n",
    "        if b < B and c < C and y < H_out and x < W_out:\n",
    "            # gốc cửa sổ pooling\n",
    "            base_y = y * S\n",
    "            base_x = x * S\n",
    "    \n",
    "            # khởi tạo max từ phần tử đầu\n",
    "            max_val = inp[b, c, base_y, base_x]\n",
    "            # quét cửa sổ K×K\n",
    "            for i in range(K):\n",
    "                for j in range(K):\n",
    "                    val = inp[b, c, base_y + i, base_x + j]\n",
    "                    if val > max_val:\n",
    "                        max_val = val\n",
    "    \n",
    "            out[b, c, y, x] = max_val\n",
    "    # Chuẩn bị output trên GPU\n",
    "    d_out = cuda.device_array((B, C, H_out, W_out), dtype=np.float32)\n",
    "    \n",
    "    bpg_x = (W_out + TPB - 1) // TPB\n",
    "    bpg_y = (H_out + TPB - 1) // TPB\n",
    "    bpg_z = B * C\n",
    "    \n",
    "    grid_dims  = (bpg_x, bpg_y, bpg_z)\n",
    "    block_dims = (TPB, TPB, 1)\n",
    "    maxpool2d_cuda[grid_dims, block_dims](\n",
    "        x, d_out\n",
    "    )\n",
    "    cuda.synchronize()\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.628608Z",
     "iopub.status.busy": "2025-08-21T03:47:51.628355Z",
     "iopub.status.idle": "2025-08-21T03:47:51.647311Z",
     "shell.execute_reply": "2025-08-21T03:47:51.646668Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.628587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_maxpooling_backward(X,LO,K=3,stride=2,TPB=16):\n",
    "    B,C,H,W = X.shape\n",
    "    B_lo,C_lo,H_lo,W_lo = LO.shape\n",
    "    @cuda.jit(cache=True)\n",
    "    def maxpooling_backward(inp,lo,out):\n",
    "        x = cuda.blockIdx.x*cuda.blockDim.x + cuda.threadIdx.x\n",
    "        y = cuda.blockIdx.y*cuda.blockDim.y + cuda.threadIdx.y\n",
    "        z = cuda.blockIdx.z\n",
    "        b = z//C\n",
    "        c = z%C\n",
    "        if x < W_lo and y < H_lo:\n",
    "            basex= x*stride\n",
    "            basey= y*stride\n",
    "            maxval = -1e20\n",
    "            for i in range(K):\n",
    "                for j in range(K):\n",
    "                    val = inp[b, c, basey + i, basex + j]\n",
    "                    if val > maxval:\n",
    "                        maxval=val\n",
    "                        index_y = basey + i\n",
    "                        index_x = basex + j\n",
    "            cuda.atomic.add(out, (b, c, index_y, index_x), lo[b, c, y, x])           \n",
    "    # dout = cuda.device_array((B,C,H,W),dtype = np.float32)\n",
    "    dout = cuda.to_device(np.zeros((B,C,H,W),dtype=np.float32))\n",
    "    # dout[:,:,:,:]=0\n",
    "    bpx = (W_lo +TPB -1)//TPB\n",
    "    bpy = (H_lo +TPB -1)//TPB\n",
    "    bpz = B_lo * C_lo\n",
    "    griddim = (bpx,bpy,bpz)\n",
    "    blockdim = (TPB,TPB,1)\n",
    "    maxpooling_backward[griddim,blockdim](X,LO,dout)\n",
    "    cuda.synchronize()\n",
    "    return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.648236Z",
     "iopub.status.busy": "2025-08-21T03:47:51.648012Z",
     "iopub.status.idle": "2025-08-21T03:47:51.667188Z",
     "shell.execute_reply": "2025-08-21T03:47:51.666527Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.648220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_concat_cuda(x_np_1,x_np_2,TPB=16):\n",
    "    B, C, H, W = x_np_1.shape\n",
    "    C_out = C*2\n",
    "    @cuda.jit(cache=True)\n",
    "    def Concat_Cuda(inp_1,inp_2, out):\n",
    "        # merge batch và channel vào blockIdx.z\n",
    "        z = cuda.blockIdx.z\n",
    "        b = z // C_out\n",
    "        c = z % C_out\n",
    "    \n",
    "        # tọa độ output\n",
    "        x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        y = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "        if y<H and x<W:\n",
    "            if c<C:\n",
    "                out[b, c, y, x] = inp_1[b, c, y, x];\n",
    "            else:\n",
    "                out[b, c, y, x] = inp_2[b, c-C, y, x]\n",
    "    \n",
    "    d_out = cuda.device_array((B, C_out, H, W), dtype=np.float32)\n",
    "    bpg_x = (H + TPB - 1) // TPB\n",
    "    bpg_y = (W + TPB - 1) // TPB\n",
    "    bpg_z = B * C_out\n",
    "     \n",
    "    grid_dims  = (bpg_x, bpg_y, bpg_z)\n",
    "    block_dims = (TPB, TPB, 1)\n",
    "\n",
    "    Concat_Cuda[grid_dims, block_dims](\n",
    "        x_np_1,x_np_2, d_out\n",
    "    )\n",
    "    cuda.synchronize()\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.668704Z",
     "iopub.status.busy": "2025-08-21T03:47:51.668005Z",
     "iopub.status.idle": "2025-08-21T03:47:51.683604Z",
     "shell.execute_reply": "2025-08-21T03:47:51.682897Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.668686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_sum_matrix(inp_1,inp_2,TPB=16):\n",
    "    B,C,H,W = inp_1.shape\n",
    "    bpx = (H + TPB - 1)//TPB\n",
    "    bpy = (W + TPB - 1)//TPB\n",
    "    @cuda.jit(cache = True)\n",
    "    def sum_matrix(matrix_1,matrix_2,out):\n",
    "        x = cuda.blockIdx.x*cuda.blockDim.x + cuda.threadIdx.x\n",
    "        y = cuda.blockIdx.y*cuda.blockDim.y + cuda.threadIdx.y\n",
    "        z = cuda.blockIdx.z\n",
    "        b = z//C\n",
    "        c = z%C\n",
    "        if x<H and y<W:\n",
    "            out[b,c,y,x] = matrix_1[b,c,y,x] + matrix_2[b,c,y,x]\n",
    "    dout = cuda.device_array((B,C,H,W),dtype = np.float32)\n",
    "    bpz = B*C\n",
    "    griddim = (bpx,bpy,bpz)\n",
    "    blockdim = (TPB,TPB,1)\n",
    "    sum_matrix[griddim,blockdim](inp_1,inp_2,dout)\n",
    "    cuda.synchronize()\n",
    "    return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.684497Z",
     "iopub.status.busy": "2025-08-21T03:47:51.684276Z",
     "iopub.status.idle": "2025-08-21T03:47:51.698204Z",
     "shell.execute_reply": "2025-08-21T03:47:51.697538Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.684475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fire_module_cuda(x,s_w1,s_b1,e_w1,e_b1,e_w3,e_b3):\n",
    "    squeeze = run_conv2d_cuda(x, s_w1, s_b1,P=0, S=1, TPB=16)                   #8x96x55x55 ==> 8x16x55x55\n",
    "    relu_squeeze = run_Relu_Cuda(squeeze,TPB=16)                            #8x16x55x55\n",
    "    expand_1x1_cu = run_conv2d_cuda(relu_squeeze, e_w1, e_b1,P=0, S=1, TPB=16)    #8x16x55x55 ==> 8x64x55x55\n",
    "    expand_3x3_cu = run_conv2d_cuda(relu_squeeze, e_w3, e_b3,P=1, S=1, TPB=16)   #8x16x55x55 ==> 8x64x55x55\n",
    "    concat = run_concat_cuda(expand_1x1_cu,expand_3x3_cu,TPB=16)                            #8x128x55x55\n",
    "    firemodule_out=run_Relu_Cuda(concat,TPB=16)\n",
    "    return {\n",
    "        \"squeeze\":squeeze,\n",
    "        \"relu_squeeze\":relu_squeeze,\n",
    "        \"expand_1x1\":expand_1x1_cu,\n",
    "        \"expand_3x3\":expand_3x3_cu,\n",
    "        \"concat\":concat,\n",
    "        \"firemodule_out\":firemodule_out\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.699124Z",
     "iopub.status.busy": "2025-08-21T03:47:51.698933Z",
     "iopub.status.idle": "2025-08-21T03:47:51.716309Z",
     "shell.execute_reply": "2025-08-21T03:47:51.715708Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.699109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_firemodule_backward(X_previous_layer,\n",
    "                            weights_squeeze1x1,bias_squeeze1x1,\n",
    "                            X_squeeze,X_relu_squeeze,\n",
    "                            weights_expand1x1,bias_expand1x1,\n",
    "                            weights_expand3x3,bias_expand3x3,\n",
    "                            X_concat,LO):\n",
    "    L_concat = run_relu_backward(X_concat,LO,TPB=16)\n",
    "    C_out = L_concat.shape[1]//2\n",
    "    L_e_1,L_e_3 = L_concat[:, :C_out, :, :], L_concat[:, C_out:, :, :]\n",
    "    LX_1_out,LF_W_1_out,LF_B_1_out = run_conv_backward(X_relu_squeeze,weights_expand1x1,bias_expand1x1,L_e_1,stride=1,padding=0, TPB=16)\n",
    "    LX_3_out,LF_W_3_out,LF_B_3_out = run_conv_backward(X_relu_squeeze,weights_expand3x3,bias_expand3x3,L_e_3,stride=1,padding=1,TPB=16)\n",
    "    sum_matrix = run_sum_matrix(LX_3_out,LX_1_out,TPB=16)\n",
    "    S_1x1 = run_relu_backward(X_squeeze,sum_matrix,TPB=16)\n",
    "    LX_pre_out,LF_pre_out,LB_pre_out = run_conv_backward(X_previous_layer,weights_squeeze1x1,bias_squeeze1x1,S_1x1,stride=1,padding=0, TPB=16)\n",
    "    return {\"LO\":LX_pre_out,\n",
    "            \"LF_s1x1\":LF_pre_out,\n",
    "            \"LB_s1x1\":LB_pre_out,\n",
    "            \"LF_e1x1\":LF_W_1_out,\n",
    "            \"LB_e1x1\":LF_B_1_out,\n",
    "            \"LF_e3x3\":LF_W_3_out,\n",
    "            \"LB_e3x3\":LF_B_3_out,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.717089Z",
     "iopub.status.busy": "2025-08-21T03:47:51.716909Z",
     "iopub.status.idle": "2025-08-21T03:47:51.735864Z",
     "shell.execute_reply": "2025-08-21T03:47:51.735204Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.717075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def squeezenet_forward_cuda(x_cuda,weights_cuda):\n",
    "    conv1           = run_conv2d_cuda_shared_2(x_cuda, weights_cuda['features.0.weight'],weights_cuda['features.0.bias'],P=3, S=2, TPB=16)\n",
    "    conv1_relu      = run_Relu_Cuda(conv1,TPB=16)\n",
    "    maxpool1     = run_maxpool2d_cuda(conv1_relu,P=0, S=2, TPB=32)\n",
    "    ########################-----Fire2----##################################\n",
    "    prefix = f'features.{3}'\n",
    "    sw = weights_cuda[f'{prefix}.squeeze.weight']\n",
    "    sb = weights_cuda[f'{prefix}.squeeze.bias']     \n",
    "    ew1 = weights_cuda[f'{prefix}.expand1x1.weight']\n",
    "    eb1 = weights_cuda[f'{prefix}.expand1x1.bias']\n",
    "    ew3 = weights_cuda[f'{prefix}.expand3x3.weight']\n",
    "    eb3 = weights_cuda[f'{prefix}.expand3x3.bias']\n",
    "    TPB = [16,16,16,16,16,16]\n",
    "    fire2=fire_module_cuda(maxpool1,sw,sb,ew1,eb1,ew3,eb3)\n",
    "    ########################-----Fire2----##################################\n",
    "    ########################-----Fire3----##################################\n",
    "    prefix = f'features.{4}'\n",
    "    sw = weights_cuda[f'{prefix}.squeeze.weight']\n",
    "    sb = weights_cuda[f'{prefix}.squeeze.bias']\n",
    "    ew1 = weights_cuda[f'{prefix}.expand1x1.weight']\n",
    "    eb1 = weights_cuda[f'{prefix}.expand1x1.bias']\n",
    "    ew3 = weights_cuda[f'{prefix}.expand3x3.weight']\n",
    "    eb3 = weights_cuda[f'{prefix}.expand3x3.bias']\n",
    "    TPB = [16,16,16,16,16,16]\n",
    "    fire3=fire_module_cuda(fire2[\"firemodule_out\"],sw,sb,ew1,eb1,ew3,eb3)\n",
    "    ########################-----Fire3----##################################\n",
    "    ########################-----Fire4----##################################\n",
    "    prefix = f'features.{5}'\n",
    "    sw = weights_cuda[f'{prefix}.squeeze.weight']\n",
    "    sb = weights_cuda[f'{prefix}.squeeze.bias']\n",
    "    ew1 = weights_cuda[f'{prefix}.expand1x1.weight']\n",
    "    eb1 = weights_cuda[f'{prefix}.expand1x1.bias']\n",
    "    ew3 = weights_cuda[f'{prefix}.expand3x3.weight']\n",
    "    eb3 = weights_cuda[f'{prefix}.expand3x3.bias']\n",
    "    TPB = [16,16,16,16,16,16]\n",
    "    fire4=fire_module_cuda(fire3[\"firemodule_out\"],sw,sb,ew1,eb1,ew3,eb3)\n",
    "    ########################-----Fire4----##################################\n",
    "    maxpool4     = run_maxpool2d_cuda(fire4[\"firemodule_out\"],P=0, S=2, TPB=32)\n",
    "    ########################-----Fire5----##################################\n",
    "    prefix = f'features.{7}'\n",
    "    sw = weights_cuda[f'{prefix}.squeeze.weight']\n",
    "    sb = weights_cuda[f'{prefix}.squeeze.bias']\n",
    "    ew1 = weights_cuda[f'{prefix}.expand1x1.weight']\n",
    "    eb1 = weights_cuda[f'{prefix}.expand1x1.bias']\n",
    "    ew3 = weights_cuda[f'{prefix}.expand3x3.weight']\n",
    "    eb3 = weights_cuda[f'{prefix}.expand3x3.bias']\n",
    "    TPB = [16,16,16,16,16,16]\n",
    "    fire5=fire_module_cuda(maxpool4,sw,sb,ew1,eb1,ew3,eb3)\n",
    "    ########################-----Fire5----##################################\n",
    "    ########################-----Fire6----##################################\n",
    "    prefix = f'features.{8}'\n",
    "    sw = weights_cuda[f'{prefix}.squeeze.weight']\n",
    "    sb = weights_cuda[f'{prefix}.squeeze.bias']\n",
    "    ew1 = weights_cuda[f'{prefix}.expand1x1.weight']\n",
    "    eb1 = weights_cuda[f'{prefix}.expand1x1.bias']\n",
    "    ew3 = weights_cuda[f'{prefix}.expand3x3.weight']\n",
    "    eb3 = weights_cuda[f'{prefix}.expand3x3.bias']\n",
    "    TPB = [16,16,16,16,16,16]\n",
    "    fire6=fire_module_cuda(fire5[\"firemodule_out\"],sw,sb,ew1,eb1,ew3,eb3)\n",
    "    ########################-----Fire6----##################################\n",
    "    ########################-----Fire7----##################################\n",
    "    prefix = f'features.{9}'\n",
    "    sw = weights_cuda[f'{prefix}.squeeze.weight']\n",
    "    sb = weights_cuda[f'{prefix}.squeeze.bias']\n",
    "    ew1 = weights_cuda[f'{prefix}.expand1x1.weight']\n",
    "    eb1 = weights_cuda[f'{prefix}.expand1x1.bias']\n",
    "    ew3 = weights_cuda[f'{prefix}.expand3x3.weight']\n",
    "    eb3 = weights_cuda[f'{prefix}.expand3x3.bias']\n",
    "    TPB = [16,16,16,16,16,16]\n",
    "    fire7=fire_module_cuda(fire6[\"firemodule_out\"],sw,sb,ew1,eb1,ew3,eb3)\n",
    "    ########################-----Fire7----##################################\n",
    "    ########################-----Fire8----##################################\n",
    "    prefix = f'features.{10}'\n",
    "    sw = weights_cuda[f'{prefix}.squeeze.weight']\n",
    "    sb = weights_cuda[f'{prefix}.squeeze.bias']\n",
    "    ew1 = weights_cuda[f'{prefix}.expand1x1.weight']\n",
    "    eb1 = weights_cuda[f'{prefix}.expand1x1.bias']\n",
    "    ew3 = weights_cuda[f'{prefix}.expand3x3.weight']\n",
    "    eb3 = weights_cuda[f'{prefix}.expand3x3.bias']\n",
    "    TPB = [16,16,16,16,16,16]\n",
    "    fire8=fire_module_cuda(fire7[\"firemodule_out\"],sw,sb,ew1,eb1,ew3,eb3)\n",
    "    ########################-----Fire8----##################################\n",
    "    maxpool8     = run_maxpool2d_cuda(fire8[\"firemodule_out\"],P=0, S=2, TPB=32)\n",
    "    ########################-----Fire9----##################################\n",
    "    prefix = f'features.{12}'\n",
    "    sw = weights_cuda[f'{prefix}.squeeze.weight']\n",
    "    sb = weights_cuda[f'{prefix}.squeeze.bias']\n",
    "    ew1 = weights_cuda[f'{prefix}.expand1x1.weight']\n",
    "    eb1 = weights_cuda[f'{prefix}.expand1x1.bias']\n",
    "    ew3 = weights_cuda[f'{prefix}.expand3x3.weight']\n",
    "    eb3 = weights_cuda[f'{prefix}.expand3x3.bias']\n",
    "    TPB = [16,16,16,16,16,16]\n",
    "    fire9=fire_module_cuda(maxpool8,sw,sb,ew1,eb1,ew3,eb3)\n",
    "    ########################-----Fire9----##################################\n",
    "    conv10 = run_conv2d_cuda(fire9[\"firemodule_out\"],weights_cuda['classifier.0.weight'],weights_cuda['classifier.0.bias'],P=0, S=1, TPB=16)\n",
    "    avgpool10     = run_global_average_Cuda(conv10,TPB=32)\n",
    "    # output = run_softmax_cuda(avgpool10)\n",
    "    return {\n",
    "        'conv1': conv1,\n",
    "        'conv1_relu': conv1_relu,\n",
    "        'maxpool1': maxpool1,\n",
    "        'fire2': fire2,\n",
    "        'fire3': fire3,\n",
    "        'fire4': fire4,\n",
    "        'maxpool4': maxpool4,\n",
    "        'fire5': fire5,\n",
    "        'fire6': fire6,\n",
    "        'fire7': fire7,\n",
    "        'fire8': fire8,\n",
    "        'maxpool8': maxpool8,\n",
    "        'fire9': fire9,\n",
    "        'conv10': conv10,\n",
    "        'avgpool10': avgpool10,\n",
    "        # \"output\":output\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.736769Z",
     "iopub.status.busy": "2025-08-21T03:47:51.736554Z",
     "iopub.status.idle": "2025-08-21T03:47:51.758776Z",
     "shell.execute_reply": "2025-08-21T03:47:51.758152Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.736746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def backward_squeezenet_cuda(X_input,X,weight,Y_cuda):\n",
    "    X_output = run_softmax_cuda(X[\"avgpool10\"])\n",
    "    avgpool10_lo = run_softmax_backward(X_output,Y_cuda)\n",
    "    conv10_lo = run_avgpool_backward(avgpool10_lo)\n",
    "    fire9_lo,conv10_lw,conv10_lb=run_conv_backward(X[\"fire9\"][\"firemodule_out\"],\n",
    "                                                   weight[\"classifier.0.weight\"], weight[\"classifier.0.bias\"],\n",
    "                                                   conv10_lo,\n",
    "                                                   stride=1,padding=0,TPB=16)\n",
    "    maxpool8_lo = run_firemodule_backward(X[\"maxpool8\"],\n",
    "                                            weight[\"features.12.squeeze.weight\"],weight[\"features.12.squeeze.bias\"],\n",
    "                                            \n",
    "                                            X[\"fire9\"][\"squeeze\"],X[\"fire9\"][\"relu_squeeze\"],\n",
    "                                            weight[\"features.12.expand1x1.weight\"],weight[\"features.12.expand1x1.bias\"],\n",
    "                                            \n",
    "                                            weight[\"features.12.expand3x3.weight\"],weight[\"features.12.expand3x3.bias\"],\n",
    "                                            \n",
    "                                            X[\"fire9\"][\"concat\"],fire9_lo)\n",
    "    fire8_lo = run_maxpooling_backward(X[\"fire8\"][\"firemodule_out\"],maxpool8_lo[\"LO\"],K=3,stride=2)\n",
    "    fire7_lo = run_firemodule_backward(X[\"fire7\"][\"firemodule_out\"],\n",
    "                                                 weight[\"features.10.squeeze.weight\"],weight[\"features.10.squeeze.bias\"],\n",
    "                                             \n",
    "                                                 X[\"fire8\"][\"squeeze\"],X[\"fire8\"][\"relu_squeeze\"],\n",
    "                                                 weight[\"features.10.expand1x1.weight\"],weight[\"features.10.expand1x1.bias\"],\n",
    "                                                 \n",
    "                                                 weight[\"features.10.expand3x3.weight\"],weight[\"features.10.expand3x3.bias\"],\n",
    "                                                 \n",
    "                                                 X[\"fire8\"][\"concat\"],fire8_lo)\n",
    "    fire6_lo = run_firemodule_backward(X[\"fire6\"][\"firemodule_out\"],\n",
    "                                                 weight[\"features.9.squeeze.weight\"],weight[\"features.9.squeeze.bias\"],\n",
    "                                                 \n",
    "                                                 X[\"fire7\"][\"squeeze\"],X[\"fire7\"][\"relu_squeeze\"],\n",
    "                                                 weight[\"features.9.expand1x1.weight\"],weight[\"features.9.expand1x1.bias\"],\n",
    "                                                 \n",
    "                                                 weight[\"features.9.expand3x3.weight\"],weight[\"features.9.expand3x3.bias\"],\n",
    "                                                 \n",
    "                                                 X[\"fire7\"][\"concat\"],fire7_lo[\"LO\"])\n",
    "    fire5_lo = run_firemodule_backward(X[\"fire5\"][\"firemodule_out\"],\n",
    "                                                 weight[\"features.8.squeeze.weight\"],weight[\"features.8.squeeze.bias\"],\n",
    "                                                 \n",
    "                                                 X[\"fire6\"][\"squeeze\"],X[\"fire6\"][\"relu_squeeze\"],\n",
    "                                                 weight[\"features.8.expand1x1.weight\"],weight[\"features.8.expand1x1.bias\"],\n",
    "                                                 \n",
    "                                                 weight[\"features.8.expand3x3.weight\"],weight[\"features.8.expand3x3.bias\"],\n",
    "                                                  \n",
    "                                                 X[\"fire6\"][\"concat\"],fire6_lo[\"LO\"])\n",
    "    maxpool4_lo = run_firemodule_backward(X[\"maxpool4\"],\n",
    "                                                 weight[\"features.7.squeeze.weight\"],weight[\"features.7.squeeze.bias\"],\n",
    "                                                 \n",
    "                                                 X[\"fire5\"][\"squeeze\"],X[\"fire5\"][\"relu_squeeze\"],\n",
    "                                                 weight[\"features.7.expand1x1.weight\"],weight[\"features.7.expand1x1.bias\"],\n",
    "                                                 \n",
    "                                                 weight[\"features.7.expand3x3.weight\"],weight[\"features.7.expand3x3.bias\"],\n",
    "                                                 \n",
    "                                                 X[\"fire5\"][\"concat\"],fire5_lo[\"LO\"])\n",
    "    fire4_lo = run_maxpooling_backward(X[\"fire4\"][\"firemodule_out\"],maxpool4_lo[\"LO\"],K=3,stride=2)\n",
    "    fire3_lo = run_firemodule_backward(X[\"fire3\"][\"firemodule_out\"],\n",
    "                                                 weight[\"features.5.squeeze.weight\"],weight[\"features.5.squeeze.bias\"],\n",
    "                                                 \n",
    "                                                 X[\"fire4\"][\"squeeze\"],X[\"fire4\"][\"relu_squeeze\"],\n",
    "                                                 weight[\"features.5.expand1x1.weight\"],weight[\"features.5.expand1x1.bias\"],\n",
    "                                                 \n",
    "                                                 weight[\"features.5.expand3x3.weight\"],weight[\"features.5.expand3x3.bias\"],\n",
    "                                                 \n",
    "                                                 X[\"fire4\"][\"concat\"],fire4_lo)\n",
    "    fire2_lo = run_firemodule_backward(X[\"fire2\"][\"firemodule_out\"],\n",
    "                                                 weight[\"features.4.squeeze.weight\"],weight[\"features.4.squeeze.bias\"],\n",
    "                                                 \n",
    "                                                 X[\"fire3\"][\"squeeze\"],X[\"fire3\"][\"relu_squeeze\"],\n",
    "                                                 weight[\"features.4.expand1x1.weight\"],weight[\"features.4.expand1x1.bias\"],\n",
    "                                                 \n",
    "                                                 weight[\"features.4.expand3x3.weight\"],weight[\"features.4.expand3x3.bias\"],\n",
    "                                                 \n",
    "                                                 X[\"fire3\"][\"concat\"],fire3_lo[\"LO\"])\n",
    "    maxpool1_lo = run_firemodule_backward(X[\"maxpool1\"],\n",
    "                                             weight[\"features.3.squeeze.weight\"],weight[\"features.3.squeeze.bias\"],\n",
    "                                             \n",
    "                                             X[\"fire2\"][\"squeeze\"],X[\"fire2\"][\"relu_squeeze\"],\n",
    "                                             weight[\"features.3.expand1x1.weight\"],weight[\"features.3.expand1x1.bias\"],\n",
    "                                             \n",
    "                                             weight[\"features.3.expand3x3.weight\"],weight[\"features.3.expand3x3.bias\"],\n",
    "                                             \n",
    "                                             X[\"fire2\"][\"concat\"],fire2_lo[\"LO\"])\n",
    "    conv1_relu_lo = run_maxpooling_backward(X[\"conv1_relu\"],maxpool1_lo[\"LO\"],K=3,stride=2)\n",
    "    conv1_lo = run_relu_backward(X[\"conv1\"],conv1_relu_lo,TPB=16)\n",
    "    # input_image_loss = run_conv_backward(x_cuda,weight[\"features.0.weight\"],weight[\"features.0.bias\"],conv1_lo,stride=2,padding=3, TPB=16)\n",
    "    bias_backward =  run_bias_backward(conv1_lo,weight[\"features.0.bias\"])\n",
    "    F_backward = run_filter_conv_backward(X_input,weight[\"features.0.weight\"],conv1_lo,2,3)\n",
    "    # X_backward = run_input_conv_backward(X,F,LO,stride,padding,TPB)\n",
    "    # bias_backward =  run_bias_backward(LO,B)\n",
    "    return { 'features.0.weight':F_backward,\n",
    "             'features.0.bias':   bias_backward,\n",
    "             'features.3.squeeze.weight': maxpool1_lo[\"LF_s1x1\"],\n",
    "             'features.3.squeeze.bias': maxpool1_lo[\"LB_s1x1\"],\n",
    "             'features.3.expand1x1.weight': maxpool1_lo[\"LF_e1x1\"],\n",
    "             'features.3.expand1x1.bias': maxpool1_lo[\"LB_e1x1\"],\n",
    "             'features.3.expand3x3.weight': maxpool1_lo[\"LF_e3x3\"],\n",
    "             'features.3.expand3x3.bias':maxpool1_lo[\"LB_e3x3\"],\n",
    "             'features.4.squeeze.weight': fire2_lo[\"LF_s1x1\"],\n",
    "             'features.4.squeeze.bias': fire2_lo[\"LB_s1x1\"],\n",
    "             'features.4.expand1x1.weight': fire2_lo[\"LF_e1x1\"],\n",
    "             'features.4.expand1x1.bias': fire2_lo[\"LB_e1x1\"],\n",
    "             'features.4.expand3x3.weight': fire2_lo[\"LF_e3x3\"],\n",
    "             'features.4.expand3x3.bias':fire2_lo[\"LB_e3x3\"],\n",
    "             'features.5.squeeze.weight': fire3_lo[\"LF_s1x1\"],\n",
    "             'features.5.squeeze.bias': fire3_lo[\"LB_s1x1\"],\n",
    "             'features.5.expand1x1.weight': fire3_lo[\"LF_e1x1\"],\n",
    "             'features.5.expand1x1.bias': fire3_lo[\"LB_e1x1\"],\n",
    "             'features.5.expand3x3.weight': fire3_lo[\"LF_e3x3\"],\n",
    "             'features.5.expand3x3.bias':fire3_lo[\"LB_e3x3\"],\n",
    "             'features.7.squeeze.weight': maxpool4_lo[\"LF_s1x1\"],\n",
    "             'features.7.squeeze.bias': maxpool4_lo[\"LB_s1x1\"],\n",
    "             'features.7.expand1x1.weight': maxpool4_lo[\"LF_e1x1\"],\n",
    "             'features.7.expand1x1.bias': maxpool4_lo[\"LB_e1x1\"],\n",
    "             'features.7.expand3x3.weight': maxpool4_lo[\"LF_e3x3\"],\n",
    "             'features.7.expand3x3.bias':maxpool4_lo[\"LB_e3x3\"],\n",
    "             'features.8.squeeze.weight': fire5_lo[\"LF_s1x1\"],\n",
    "             'features.8.squeeze.bias': fire5_lo[\"LB_s1x1\"],\n",
    "             'features.8.expand1x1.weight': fire5_lo[\"LF_e1x1\"],\n",
    "             'features.8.expand1x1.bias': fire5_lo[\"LB_e1x1\"],\n",
    "             'features.8.expand3x3.weight': fire5_lo[\"LF_e3x3\"],\n",
    "             'features.8.expand3x3.bias':fire5_lo[\"LB_e3x3\"],\n",
    "             'features.9.squeeze.weight': fire6_lo[\"LF_s1x1\"],\n",
    "             'features.9.squeeze.bias': fire6_lo[\"LB_s1x1\"],\n",
    "             'features.9.expand1x1.weight': fire6_lo[\"LF_e1x1\"],\n",
    "             'features.9.expand1x1.bias': fire6_lo[\"LB_e1x1\"],\n",
    "             'features.9.expand3x3.weight': fire6_lo[\"LF_e3x3\"],\n",
    "             'features.9.expand3x3.bias':fire6_lo[\"LB_e3x3\"],\n",
    "             'features.10.squeeze.weight': fire7_lo[\"LF_s1x1\"],\n",
    "             'features.10.squeeze.bias': fire7_lo[\"LB_s1x1\"],\n",
    "             'features.10.expand1x1.weight': fire7_lo[\"LF_e1x1\"],\n",
    "             'features.10.expand1x1.bias': fire7_lo[\"LB_e1x1\"],\n",
    "             'features.10.expand3x3.weight': fire7_lo[\"LF_e3x3\"],\n",
    "             'features.10.expand3x3.bias':fire7_lo[\"LB_e3x3\"],\n",
    "             'features.12.squeeze.weight': maxpool8_lo[\"LF_s1x1\"],\n",
    "             'features.12.squeeze.bias': maxpool8_lo[\"LB_s1x1\"],\n",
    "             'features.12.expand1x1.weight': maxpool8_lo[\"LF_e1x1\"],\n",
    "             'features.12.expand1x1.bias': maxpool8_lo[\"LB_e1x1\"],\n",
    "             'features.12.expand3x3.weight': maxpool8_lo[\"LF_e3x3\"],\n",
    "             'features.12.expand3x3.bias':maxpool8_lo[\"LB_e3x3\"],\n",
    "             'classifier.0.weight': conv10_lw,\n",
    "             'classifier.0.bias': conv10_lb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.759602Z",
     "iopub.status.busy": "2025-08-21T03:47:51.759382Z",
     "iopub.status.idle": "2025-08-21T03:47:51.777143Z",
     "shell.execute_reply": "2025-08-21T03:47:51.776480Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.759587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class Fire(nn.Module):\n",
    "    def __init__(self, in_channels, squeeze_channels, expand1x1_channels, expand3x3_channels):\n",
    "        super().__init__()\n",
    "        self.squeeze      = nn.Conv2d(in_channels, squeeze_channels, kernel_size=1)\n",
    "        self.expand1x1    = nn.Conv2d(squeeze_channels, expand1x1_channels, kernel_size=1)\n",
    "        self.expand3x3    = nn.Conv2d(squeeze_channels, expand3x3_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x, return_intermediates=False):\n",
    "        squeeze_out = self.squeeze(x)\n",
    "        relu_squeeze = F.relu(squeeze_out)\n",
    "        expand1x1_out = self.expand1x1(relu_squeeze)\n",
    "        expand3x3_out = self.expand3x3(relu_squeeze)\n",
    "        concat = torch.cat([expand1x1_out, expand3x3_out], dim=1)\n",
    "        fire_out = F.relu(concat)\n",
    "        return fire_out\n",
    "class SqueezeNetManual(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=7, stride=2, padding=3),  # conv1\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # maxpool1\n",
    "\n",
    "            Fire(96,  16,  64,  64),   # fire2\n",
    "            Fire(128, 16,  64,  64),   # fire3\n",
    "            Fire(128, 32, 128, 128),   # fire4\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # maxpool4\n",
    "\n",
    "            Fire(256, 32, 128, 128),   # fire5\n",
    "            Fire(256, 48, 192, 192),   # fire6\n",
    "            Fire(384, 48, 192, 192),   # fire7\n",
    "            Fire(384, 64, 256, 256),   # fire8\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                  # maxpool8\n",
    "\n",
    "            Fire(512, 64, 256, 256),   # fire9\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(512, num_classes, kernel_size=1),            # conv10\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # === Thêm: Lưu gradient ===\n",
    "        self.gradients = {}\n",
    "        self._register_gradient_hooks()\n",
    "\n",
    "    def _register_gradient_hooks(self):\n",
    "        \"\"\"\n",
    "        Đăng ký backward hook cho tất cả các tham số có requires_grad=True\n",
    "        \"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            def make_hook(name):\n",
    "                def hook(grad):\n",
    "                    self.gradients[name] = grad.clone()  # Lưu bản sao của gradient\n",
    "                return hook\n",
    "\n",
    "            param.register_hook(make_hook(name))\n",
    "\n",
    "    def clear_gradients(self):\n",
    "        \"\"\"Xóa gradient đã lưu từ bước trước\"\"\"\n",
    "        self.gradients.clear()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        x = self.avgpool(x)\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:47:51.778227Z",
     "iopub.status.busy": "2025-08-21T03:47:51.777951Z",
     "iopub.status.idle": "2025-08-21T03:48:18.138716Z",
     "shell.execute_reply": "2025-08-21T03:48:18.138084Z",
     "shell.execute_reply.started": "2025-08-21T03:47:51.778206Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DIR_ROOT = '/kaggle/input/tomato-diseases'\n",
    "DIR_TRAIN = os.path.join(DIR_ROOT, 'train')\n",
    "DIR_TEST  = os.path.join(DIR_ROOT, 'test')\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224),        # bilinear là mặc định cho Resize\n",
    "                       interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),              # → FloatTensor trong [0,1]\n",
    "    transforms.Lambda(lambda x: x * 2.0 - 1.0),  # → FloatTensor trong [-1,1]\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(DIR_TRAIN, transform=transform)\n",
    "test_ds  = datasets.ImageFolder(DIR_TEST,  transform=transform)\n",
    "categories = train_ds.classes  # danh sách tên lớp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:48:18.139701Z",
     "iopub.status.busy": "2025-08-21T03:48:18.139452Z",
     "iopub.status.idle": "2025-08-21T03:48:18.144796Z",
     "shell.execute_reply": "2025-08-21T03:48:18.144109Z",
     "shell.execute_reply.started": "2025-08-21T03:48:18.139675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE     = 32\n",
    "SHUFFLE        = True\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,           # thường không shuffle validation\n",
    ")\n",
    "\n",
    "# Kiểm tra nhanh:\n",
    "print(f'Number of training samples: {len(train_loader)}')\n",
    "print(f'Number of validation samples: {len(val_loader)}')\n",
    "print(f'Classes: {categories}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:48:49.128262Z",
     "iopub.status.busy": "2025-08-21T03:48:49.127972Z",
     "iopub.status.idle": "2025-08-21T03:48:49.139569Z",
     "shell.execute_reply": "2025-08-21T03:48:49.138921Z",
     "shell.execute_reply.started": "2025-08-21T03:48:49.128241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "load_state_5 = np.load(\"/kaggle/input/epoch_30_sgd/other/default/1/model_data_SGD_epoch_25.npz\",allow_pickle=True)\n",
    "weights_np = {k: v for k, v in load_state_5[\"weights\"].item().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T03:48:52.933880Z",
     "iopub.status.busy": "2025-08-21T03:48:52.933608Z",
     "iopub.status.idle": "2025-08-21T03:51:24.816821Z",
     "shell.execute_reply": "2025-08-21T03:51:24.816107Z",
     "shell.execute_reply.started": "2025-08-21T03:48:52.933860Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "epochs = 5\n",
    "Loss_container = []\n",
    "Acc_container = []\n",
    "for epoch in range(epochs):\n",
    "    print(weights_np[\"classifier.0.bias\"].flatten())\n",
    "    print(cuda.current_context().get_memory_info())\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    weights_cuda = {k: cuda.to_device(v) for k, v in weights_np.items()}\n",
    "    running_loss, running_corr, running_samples = 0.0, 0, 0\n",
    "    train_iter = tqdm(train_loader, desc=f\"[Epoch {epoch}/{epochs}] Training\", leave=False)\n",
    "    for imgs, labels in train_iter:\n",
    "        x_cuda = cuda.to_device(imgs.cpu().numpy())\n",
    "        y_np   = labels.cpu().numpy()\n",
    "        # One-hot encode\n",
    "        Y = np.zeros((y_np.size, 10), dtype=np.float32)\n",
    "        Y[np.arange(y_np.size), y_np] = 1\n",
    "        Y_cuda = cuda.to_device(Y)\n",
    "        \n",
    "        # Forward\n",
    "        #X_forward = squeezenet_forward_cuda(x_cuda,weights_cuda)\n",
    "        x_cuda_forward = squeezenet_forward_cuda(x_cuda,weights_cuda)\n",
    "        X_output = run_softmax_cuda(x_cuda_forward[\"avgpool10\"])\n",
    "\n",
    "        # Loss\n",
    "        epsilon = 1e-20\n",
    "        batch_loss = 0.0\n",
    "        for m in range(X_output.shape[0]):\n",
    "            for n in range(X_output.shape[1]):\n",
    "                if Y_cuda[m][n] == 1:\n",
    "                    batch_loss -= math.log(X_output[m][n] + epsilon)\n",
    "\n",
    "        running_loss += batch_loss\n",
    "       \n",
    "        # Accuracy\n",
    "        output_cpu = X_output.copy_to_host()\n",
    "        predicted = np.argmax(output_cpu, axis=1)\n",
    "        running_corr += np.sum(predicted == y_np)\n",
    "        running_samples += y_np.shape[0]\n",
    "        memory= cuda.current_context().get_memory_info()\n",
    "        train_iter.set_postfix(loss=running_loss / running_samples,\n",
    "                               acc=running_corr / running_samples,\n",
    "                               freemem = memory)\n",
    "        #weights_cuda =  backward_squeezenet_cuda(x_cuda,X_forward,weights_cuda,Y_cuda)\n",
    "        weights_cuda =  backward_squeezenet_cuda(x_cuda,x_cuda_forward,weights_cuda,Y_cuda)\n",
    "    train_loss = running_loss / running_samples\n",
    "    train_acc  = running_corr / running_samples\n",
    "    weights_np = {k: v.copy_to_host() for k, v in weights_cuda.items()}\n",
    "    cuda.get_current_device().reset()\n",
    "    Loss_container.append(train_loss)\n",
    "    Acc_container.append(train_acc)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | \"\n",
    "          f\"Train loss: {train_loss:.4f}, acc: {train_acc:.4f}\")\n",
    "    print(Loss_container)\n",
    "    print(Acc_container)\n",
    "np.savez(f'/kaggle/working/model_data_SGD_epoch_30.npz', \n",
    "                 weights=weights_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-21T03:48:43.052868Z",
     "iopub.status.idle": "2025-08-21T03:48:43.053079Z",
     "shell.execute_reply": "2025-08-21T03:48:43.052988Z",
     "shell.execute_reply.started": "2025-08-21T03:48:43.052979Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "# model = SqueezeNetManual(num_classes=10).to(\"cuda\",dtype=torch.float32)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.0008)\n",
    "# state = model.state_dict()\n",
    "# weights_np = {k: v.cpu().numpy() for k, v in state.items()}\n",
    "# weights_cuda = {k: cuda.to_device(v) for k, v in weights_np.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2025-08-21T03:48:43.053741Z",
     "iopub.status.idle": "2025-08-21T03:48:43.053950Z",
     "shell.execute_reply": "2025-08-21T03:48:43.053856Z",
     "shell.execute_reply.started": "2025-08-21T03:48:43.053848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# imgs,labels = next(iter(train_loader))\n",
    "# x_cuda = cuda.to_device(imgs.cpu().numpy())\n",
    "# y_np   = labels.cpu().numpy()\n",
    "# # One-hot encode\n",
    "# Y = np.zeros((y_np.size, 10), dtype=np.float32)\n",
    "# Y[np.arange(y_np.size), y_np] = 1\n",
    "# Y_cuda = cuda.to_device(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2025-08-21T03:48:43.054727Z",
     "iopub.status.idle": "2025-08-21T03:48:43.055017Z",
     "shell.execute_reply": "2025-08-21T03:48:43.054882Z",
     "shell.execute_reply.started": "2025-08-21T03:48:43.054866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# t =time.time()\n",
    "# for i in range(100):\n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(imgs.to(\"cuda\"))\n",
    "#     loss = nn.CrossEntropyLoss()(output, labels.to(\"cuda\"))\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "# t_torch = time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-21T03:48:43.056136Z",
     "iopub.status.idle": "2025-08-21T03:48:43.056338Z",
     "shell.execute_reply": "2025-08-21T03:48:43.056251Z",
     "shell.execute_reply.started": "2025-08-21T03:48:43.056242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# t = time.time()\n",
    "# for i in tqdm(range(100)):\n",
    "#     X_forward = squeezenet_forward_cuda(x_cuda,weights_cuda)\n",
    "#     weights_cuda =  backward_squeezenet_cuda(x_cuda,X_forward,weights_cuda,Y_cuda)\n",
    "# t_cu = time.time() - t"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4668294,
     "sourceId": 8067940,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 432994,
     "modelInstanceId": 415235,
     "sourceId": 531432,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
